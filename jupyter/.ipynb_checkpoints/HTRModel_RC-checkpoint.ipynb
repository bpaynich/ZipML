{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Dependencies to Visualize the model\n",
    "%matplotlib inline\n",
    "from IPython.display import Image, SVG\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "# Filepaths, numpy, and Tensorflow\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import preprocessing\n",
    "\n",
    "# Sklearn scaling\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Keras Specific Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Keras\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loading and Preprocessing our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Load the MNIST Handwriting Dataset from Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Info\n",
      "Training Data Shape: (60000, 28, 28)\n",
      "Training Data Labels Shape: (60000,)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print(\"Training Data Info\")\n",
    "print(\"Training Data Shape:\", X_train.shape)\n",
    "print(\"Training Data Labels Shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Plot the first digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a32462b70>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADmVJREFUeJzt3X+MVPW5x/HPI4KoEIOyUGLxbtuouYakWx1JDWL2UiXUNAGCNSWxoZF0G63JxRBTs39Yf+QaYi6tGE2T7QXBpLVUAcHEtCgx8ZJodfxVRdSqWcteEJaoVIjSAM/9Yw/NijvfGWbOzBn2eb8SszPnOd89jwMfzsx858zX3F0A4jmt6AYAFIPwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8I6vRWHmzy5Mne2dnZykMCofT392v//v1Wy74Nhd/M5klaJWmMpP9x9xWp/Ts7O1Uulxs5JICEUqlU8751P+03szGSHpL0fUmXSFpsZpfU+/sAtFYjr/lnSnrP3T9w939K+oOk+fm0BaDZGgn/+ZJ2Dbs/kG37EjPrMbOymZUHBwcbOByAPDUS/pHeVPjK9cHu3ufuJXcvdXR0NHA4AHlqJPwDkqYPu/91SbsbawdAqzQS/pckXWhm3zCzcZJ+JGlLPm0BaLa6p/rc/YiZ3SLpzxqa6lvj7jty6wxAUzU0z+/uT0l6KqdeALQQH+8FgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gqIZW6TWzfkmfSToq6Yi7l/JoCvk5duxYsn748OGmHn/dunUVa4cOHUqOfeutt5L1+++/P1nv7e2tWHvwwQeTY88888xkfeXKlcn6TTfdlKy3g4bCn/kPd9+fw+8B0EI87QeCajT8Lmmrmb1sZj15NASgNRp92j/L3Xeb2RRJT5vZ2+7+3PAdsn8UeiTpggsuaPBwAPLS0Jnf3XdnP/dJ2iRp5gj79Ll7yd1LHR0djRwOQI7qDr+ZnW1mE4/fljRX0pt5NQaguRp52j9V0iYzO/57fu/uf8qlKwBNV3f43f0DSd/OsZdR68CBA8n60aNHk/XXX389Wd+6dWvF2qeffpoc29fXl6wXqbOzM1lfvnx5sr569eqKtXPOOSc5dvbs2cn6nDlzkvVTAVN9QFCEHwiK8ANBEX4gKMIPBEX4gaDyuKovvIGBgWS9q6srWf/kk0/ybOeUcdpp6XNPaqpOqn7Z7dKlSyvWpkyZkhw7YcKEZH00fFqVMz8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBMU8fw7OO++8ZH3q1KnJejvP88+dOzdZr/b/vnHjxoq1M844Izm2u7s7WUdjOPMDQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFDM8+eg2nXla9euTdYff/zxZP2KK65I1hctWpSsp1x55ZXJ+ubNm5P1cePGJesfffRRxdqqVauSY9FcnPmBoAg/EBThB4Ii/EBQhB8IivADQRF+IChz9/QOZmsk/UDSPnefkW07V9J6SZ2S+iVd7+5VL0ovlUpeLpcbbHn0OXz4cLJebS69t7e3Yu2+++5Ljn322WeT9auuuipZR3splUoql8tWy761nPnXSpp3wrbbJW1z9wslbcvuAziFVA2/uz8n6eMTNs+XtC67vU7Sgpz7AtBk9b7mn+rueyQp+5le+whA22n6G35m1mNmZTMrDw4ONvtwAGpUb/j3mtk0Scp+7qu0o7v3uXvJ3UujYXFDYLSoN/xbJC3Jbi+RlL70C0DbqRp+M3tU0vOSLjazATNbKmmFpGvM7G+SrsnuAziFVL2e390XVyh9L+dewqr2/fXVTJo0qe6xDzzwQLI+e/bsZN2spilltCE+4QcERfiBoAg/EBThB4Ii/EBQhB8Iiq/uHgWWLVtWsfbiiy8mx27atClZ37FjR7I+Y8aMZB3tizM/EBThB4Ii/EBQhB8IivADQRF+ICjCDwTFPP8okPpq776+vuTYbdu2Jevz589P1hcsSH9366xZsyrWFi5cmBzL5cLNxZkfCIrwA0ERfiAowg8ERfiBoAg/EBThB4KqukR3nliiu/1Uu95/3rwTF2j+sgMHDtR97DVr1iTrixYtStYnTJhQ97FHq7yX6AYwChF+ICjCDwRF+IGgCD8QFOEHgiL8QFBVr+c3szWSfiBpn7vPyLbdKemnkgaz3Xrd/almNYnmmTlzZrJe7Xv7b7311mT9scceq1i78cYbk2Pff//9ZP22225L1idOnJisR1fLmX+tpJE+6fFrd+/K/iP4wCmmavjd/TlJH7egFwAt1Mhr/lvM7K9mtsbMJuXWEYCWqDf8v5H0LUldkvZIWllpRzPrMbOymZUHBwcr7QagxeoKv7vvdfej7n5M0m8lVXzXyN373L3k7qWOjo56+wSQs7rCb2bTht1dKOnNfNoB0Cq1TPU9Kqlb0mQzG5D0S0ndZtYlySX1S/pZE3sE0ARcz4+GfPHFF8n6Cy+8ULF29dVXJ8dW+7t53XXXJevr169P1kcjrucHUBXhB4Ii/EBQhB8IivADQRF+ICiW6EZDxo8fn6x3d3dXrI0ZMyY59siRI8n6E088kay/8847FWsXX3xxcmwEnPmBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjm+ZG0e/fuZH3jxo3J+vPPP1+xVm0ev5rLL788Wb/ooosa+v2jHWd+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiKef5RrtoSaQ899FCy/vDDDyfrAwMDJ91Trapd79/Z2Zmsm9X0DdZhceYHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaCqzvOb2XRJj0j6mqRjkvrcfZWZnStpvaROSf2Srnf3T5rXalwHDx5M1p988smKtbvvvjs59t13362rpzzMmTMnWV+xYkWyftlll+XZTji1nPmPSFru7v8u6buSfm5ml0i6XdI2d79Q0rbsPoBTRNXwu/sed38lu/2ZpJ2Szpc0X9K6bLd1khY0q0kA+Tup1/xm1inpO5L+Immqu++Rhv6BkDQl7+YANE/N4TezCZI2SFrm7v84iXE9ZlY2s3K1z5kDaJ2awm9mYzUU/N+5+/FvbNxrZtOy+jRJ+0Ya6+597l5y91JHR0cePQPIQdXw29ClUasl7XT3Xw0rbZG0JLu9RNLm/NsD0Cy1XNI7S9KPJb1hZq9l23olrZD0RzNbKunvkn7YnBZPfYcOHUrWd+3alazfcMMNyfqrr7560j3lZe7cucn6XXfdVbFW7au3uSS3uaqG3923S6r0p/C9fNsB0Cp8wg8IivADQRF+ICjCDwRF+IGgCD8QFF/dXaPPP/+8Ym3ZsmXJsdu3b0/W33777bp6ysO1116brN9xxx3JeldXV7I+duzYk+4JrcGZHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCCjPP39/fn6zfe++9yfozzzxTsfbhhx/W01JuzjrrrIq1e+65Jzn25ptvTtbHjRtXV09of5z5gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiCoMPP8GzZsSNZXr17dtGNfeumlyfrixYuT9dNPT/8x9fT0VKyNHz8+ORZxceYHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaDM3dM7mE2X9Iikr0k6JqnP3VeZ2Z2SfippMNu1192fSv2uUqnk5XK54aYBjKxUKqlcLlst+9byIZ8jkpa7+ytmNlHSy2b2dFb7tbv/d72NAihO1fC7+x5Je7Lbn5nZTknnN7sxAM11Uq/5zaxT0nck/SXbdIuZ/dXM1pjZpApjesysbGblwcHBkXYBUICaw29mEyRtkLTM3f8h6TeSviWpS0PPDFaONM7d+9y95O6ljo6OHFoGkIeawm9mYzUU/N+5+0ZJcve97n7U3Y9J+q2kmc1rE0DeqobfzEzSakk73f1Xw7ZPG7bbQklv5t8egGap5d3+WZJ+LOkNM3st29YrabGZdUlySf2SftaUDgE0RS3v9m+XNNK8YXJOH0B74xN+QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoKp+dXeuBzMblPThsE2TJe1vWQMnp117a9e+JHqrV569/Zu71/R9eS0N/1cOblZ291JhDSS0a2/t2pdEb/Uqqjee9gNBEX4gqKLD31fw8VPatbd27Uuit3oV0luhr/kBFKfoMz+AghQSfjObZ2bvmNl7ZnZ7ET1UYmb9ZvaGmb1mZoUuKZwtg7bPzN4ctu1cM3vazP6W/RxxmbSCervTzP4ve+xeM7NrC+ptupk9a2Y7zWyHmf1ntr3Qxy7RVyGPW8uf9pvZGEnvSrpG0oCklyQtdve3WtpIBWbWL6nk7oXPCZvZVZIOSnrE3Wdk2+6T9LG7r8j+4Zzk7r9ok97ulHSw6JWbswVlpg1fWVrSAkk/UYGPXaKv61XA41bEmX+mpPfc/QN3/6ekP0iaX0Afbc/dn5P08Qmb50tal91ep6G/PC1Xobe24O573P2V7PZnko6vLF3oY5foqxBFhP98SbuG3R9Qey357ZK2mtnLZtZTdDMjmJotm358+fQpBfdzoqorN7fSCStLt81jV8+K13krIvwjrf7TTlMOs9z9Uknfl/Tz7OktalPTys2tMsLK0m2h3hWv81ZE+AckTR92/+uSdhfQx4jcfXf2c5+kTWq/1Yf3Hl8kNfu5r+B+/qWdVm4eaWVptcFj104rXhcR/pckXWhm3zCzcZJ+JGlLAX18hZmdnb0RIzM7W9Jctd/qw1skLcluL5G0ucBevqRdVm6utLK0Cn7s2m3F60I+5JNNZdwvaYykNe7+Xy1vYgRm9k0Nne2loUVMf19kb2b2qKRuDV31tVfSLyU9IemPki6Q9HdJP3T3lr/xVqG3bg09df3Xys3HX2O3uLcrJf2vpDckHcs292ro9XVhj12ir8Uq4HHjE35AUHzCDwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUP8PRZ8Vlgh2BcUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the first image from the dataset\n",
    "plt.imshow(X_train[0,:,:], cmap=plt.cm.Greys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Each Image is a 28x28 Pixel greyscale image with values from 0 to 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our image is an array of pixels ranging from 0 to 255\n",
    "X_train[0, :, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### For Logistic Regression, we want to flatten our data into rows of 1D image arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shape: (60000, 784)\n",
      "Testing Shape: (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# We want to flatten our image of 28x28 pixels to a 1D array of 784 pixels\n",
    "ndims = X_train.shape[1] * X_train.shape[2]\n",
    "X_train = X_train.reshape(X_train.shape[0], ndims)\n",
    "X_test = X_test.reshape(X_test.shape[0], ndims)\n",
    "print(\"Training Shape:\", X_train.shape)\n",
    "print(\"Testing Shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Scaling and Normalization\n",
    "\n",
    "We use Sklearn's MinMaxScaler to normalize our data between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype uint8 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# Next, we normalize our training data to be between 0 and 1\n",
    "scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "# Alternative way to normalize this dataset since we know that the max pixel value is 255\n",
    "# X_train = X_train.astype(\"float32\")\n",
    "# X_test = X_test.astype(\"float32\")\n",
    "# X_train /= 255.0\n",
    "# X_test /= 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## One-Hot Encoding\n",
    "\n",
    "We need to one-hot encode our integer labels using the `to_categorical` helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our Training and Testing labels are integer encoded from 0 to 9\n",
    "y_train[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to convert our target labels (expected values) to categorical data\n",
    "num_classes = 10\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "# Original label of `5` is one-hot encoded as `0000010000`\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the model accuracy\n",
    "model_score = knn.score(X_test, y_test)\n",
    "model_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['knn_model.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save trained model\n",
    "#from joblib import dump\n",
    "import joblib\n",
    "joblib.dump(knn, 'knn_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Building our Model\n",
    "\n",
    "In this example, we are going to build a Deep Multi-Layer Perceptron model with 2 hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Our first step is to create an empty sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Create an empty sequential model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Next, we add our first hidden layer\n",
    "\n",
    "In the first hidden layer, we must also specify the dimension of our input layer. This will simply be the number of elements (pixels) in each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/PythonData/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Add the first layer where the input dimensions are the 784 pixel values\n",
    "# We can also choose our activation function. `relu` is a common\n",
    "model.add(Dense(100, activation='relu', input_dim=X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## We then add a second hidden layer with 100 densely connected nodes\n",
    "\n",
    "A dense layer is when every node from the previous layer is connected to each node in the current layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Add a second hidden layer\n",
    "model.add(Dense(100, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Our final output layer uses a `softmax` activation function for logistic regression.\n",
    "\n",
    "We also need to specify the number of output classes. In this case, the number of digits that we wish to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Add our final output layer where the number of nodes \n",
    "# corresponds to the number of y labels\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 89,610\n",
      "Trainable params: 89,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# We can summarize our model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Compile and Train our Model\n",
    "\n",
    "Now that we have our model architecture defined, we must compile the model using a loss function and optimizer. We can also specify additional training metrics such as accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Use categorical crossentropy for categorical data and mean squared error for regression\n",
    "# Hint: your output layer in this example is using software for logistic regression (categorical)\n",
    "# If your output layer activation was `linear` then you may want to use `mse` for loss\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Finally, we train our model using our training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Training consists of updating our weights using our optimizer and loss function. In this example, we choose 10 iterations (loops) of training that are called epochs.\n",
    "\n",
    "We also choose to shuffle our training data and increase the detail printed out during each training cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/PythonData/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      " - 8s - loss: 0.2418 - acc: 0.9291\n",
      "Epoch 2/10\n",
      " - 7s - loss: 0.1029 - acc: 0.9685\n",
      "Epoch 3/10\n",
      " - 8s - loss: 0.0718 - acc: 0.9776\n",
      "Epoch 4/10\n",
      " - 8s - loss: 0.0565 - acc: 0.9819\n",
      "Epoch 5/10\n",
      " - 8s - loss: 0.0431 - acc: 0.9863\n",
      "Epoch 6/10\n",
      " - 8s - loss: 0.0357 - acc: 0.9884\n",
      "Epoch 7/10\n",
      " - 7s - loss: 0.0309 - acc: 0.9901\n",
      "Epoch 8/10\n",
      " - 8s - loss: 0.0265 - acc: 0.9914\n",
      "Epoch 9/10\n",
      " - 8s - loss: 0.0218 - acc: 0.9924\n",
      "Epoch 10/10\n",
      " - 8s - loss: 0.0188 - acc: 0.9936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a857ae828>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit (train) the model\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=10,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Saving and Loading models\n",
    "\n",
    "We can save our trained models using the HDF5 binary format with the extension `.h5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"mnist_trained.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/PythonData/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda3/envs/PythonData/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"mnist_trained.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluating the Model\n",
    "\n",
    "We use our testing data to validate our model. This is how we determine the validity of our model (i.e. the ability to predict new and previously unseen data points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.0912 - acc: 0.9779\n",
      "Loss: 0.09119371017400763, Accuracy: 0.9779000282287598\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the training data \n",
    "model_loss, model_accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Making Predictions\n",
    "\n",
    "We can use our trained model to make predictions using `model.predict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 784)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab just one data point to test with\n",
    "test = np.expand_dims(X_train[0], axis=0)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a55666438>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(scaler.inverse_transform(test).reshape(28, 28), cmap=plt.cm.Greys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a prediction. The result should be 0000010000000 for a 5\n",
    "model.predict(test).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 784)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab just one data point to test with\n",
    "test = np.expand_dims(X_train[2], axis=0)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a5568b1d0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(scaler.inverse_transform(test).reshape(28, 28), cmap=plt.cm.Greys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Hot-Encoded Prediction: [[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
      "Predicted class: [4]\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction. The resulting class should match the digit\n",
    "print(f\"One-Hot-Encoded Prediction: {model.predict(test).round()}\")\n",
    "print(f\"Predicted class: {model.predict_classes(test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## executing the model on a custom image\n",
    "\n",
    "We can use our trained model to make predictions using `model.predict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"nine.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x1A2F6D0860>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "image_size = (28, 28)\n",
    "im = image.load_img(filepath, target_size=image_size, color_mode=\"grayscale\")\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the image to a numpy array \n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "image = img_to_array(im)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 784)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale the image pixels by 255 (or use a scaler from sklearn here)\n",
    "image /= 255\n",
    "\n",
    "# Flatten into a 1x28*28 array \n",
    "img = image.flatten().reshape(-1, 28*28)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a52daab38>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img.reshape(28, 28), cmap=plt.cm.Greys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a52bb6860>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Invert the pixel values to match the original data\n",
    "img = 1 - img\n",
    "plt.imshow(img.reshape(28, 28), cmap=plt.cm.Greys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "model.predict_classes(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"mnist_trained.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "filepath = \"newdig2.png\"\n",
    "from tensorflow.keras.preprocessing import image\n",
    "image_size = (28, 28)\n",
    "im = image.load_img(filepath, target_size=image_size, color_mode=\"grayscale\")\n",
    "im\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "image = img_to_array(im)\n",
    "image.shape\n",
    "# Scale the image pixels by 255 (or use a scaler from sklearn here)\n",
    "image /= 255\n",
    "\n",
    "# Flatten into a 1x28*28 array \n",
    "img = image.flatten().reshape(-1, 28*28)\n",
    "img.shape\n",
    "plt.imshow(img.reshape(28, 28), cmap=plt.cm.Greys)\n",
    "# Invert the pixel values to match the original data\n",
    "img = 1 - img\n",
    "plt.imshow(img.reshape(28, 28), cmap=plt.cm.Greys)\n",
    "# Make predictions\n",
    "model.predict_classes(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar1 = model.predict_classes(img)\n",
    "ar1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newDig(filepath):    \n",
    "    filepath = filepath\n",
    "    from tensorflow.keras.preprocessing import image\n",
    "    image_size = (28, 28)\n",
    "    im = image.load_img(filepath, target_size=image_size, color_mode=\"grayscale\")\n",
    "  #  from tensorflow.keras.preprocessing.image import img_to_array\n",
    "    image = img_to_array(im)\n",
    "    image.shape\n",
    "    # Scale the image pixels by 255 (or use a scaler from sklearn here)\n",
    "    image /= 255\n",
    "\n",
    "    # Flatten into a 1x28*28 array \n",
    "    img = image.flatten().reshape(-1, 28*28)\n",
    " #   img.shape\n",
    "    plt.imshow(img.reshape(28, 28), cmap=plt.cm.Greys)\n",
    "    # Invert the pixel values to match the original data\n",
    "    img = 1 - img\n",
    "    plt.imshow(img.reshape(28, 28), cmap=plt.cm.Greys)\n",
    "    # Make predictions\n",
    "    return model.predict_classes(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img_to_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-1162972fb52d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mar1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewDig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"newdig.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mar1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-28551b211d15>\u001b[0m in \u001b[0;36mnewDig\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"grayscale\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;31m#  from tensorflow.keras.preprocessing.image import img_to_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Scale the image pixels by 255 (or use a scaler from sklearn here)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'img_to_array' is not defined"
     ]
    }
   ],
   "source": [
    "ar1 = newDig(\"newdig.png\")\n",
    "ar1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'img_to_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c49546de832f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnewDig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"IndivDigits/1.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-28551b211d15>\u001b[0m in \u001b[0;36mnewDig\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"grayscale\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;31m#  from tensorflow.keras.preprocessing.image import img_to_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Scale the image pixels by 255 (or use a scaler from sklearn here)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'img_to_array' is not defined"
     ]
    }
   ],
   "source": [
    "from keras import preprocessing\n",
    "newDig(\"IndivDigits/1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: 'IndivDigits/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-6bed21ca0cae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mreads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mnewDig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#     print(filename)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#     image_size = (28, 28)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-9aad1a9135e0>\u001b[0m in \u001b[0;36mnewDig\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mimage_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"grayscale\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0;31m#  from tensorflow.keras.preprocessing.image import img_to_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/PythonData/lib/python3.6/site-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    102\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    103\u001b[0m                           'The use of `array_to_img` requires PIL.')\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'L'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/PythonData/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2651\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2652\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2653\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: 'IndivDigits/'"
     ]
    }
   ],
   "source": [
    "directory = \"IndivDigits/\"\n",
    "reads = []\n",
    "for filename in os.listdir(directory):\n",
    "    newDig(directory)\n",
    "#     print(filename)\n",
    "#     image_size = (28, 28)\n",
    "#     im = image.load_img(directory, target_size=image_size, color_mode=\"grayscale\")\n",
    "#   #  from tensorflow.keras.preprocessing.image import img_to_array\n",
    "#     image = img_to_array(im)\n",
    "#  #   image.shape\n",
    "#     # Scale the image pixels by 255 (or use a scaler from sklearn here)\n",
    "#     image /= 255\n",
    "\n",
    "#     # Flatten into a 1x28*28 array \n",
    "#     img = image.flatten().reshape(-1, 28*28)\n",
    "#  #   img.shape\n",
    "# #    plt.imshow(img.reshape(28, 28), cmap=plt.cm.Greys)\n",
    "#     # Invert the pixel values to match the original data\n",
    "#     img = 1 - img\n",
    "# #    plt.imshow(img.reshape(28, 28), cmap=plt.cm.Greys)\n",
    "#     # Make predictions\n",
    "#     reads.append(model.predict_classes(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-87-a4a87a18ebe2>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-87-a4a87a18ebe2>\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    print(os.fsdecode(\"IndivDigits/\"file))\u001b[0m\n\u001b[0m                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = 'IndivDigits/'\n",
    "\n",
    "# folder = os.fsencode(\"IndivDigits/\")\n",
    "# print(folder)\n",
    "\n",
    "\n",
    "\n",
    "for file in os.listdir(path):\n",
    "    print(os.fsdecode(file))\n",
    "    #filename = os.fsdecode(file)\n",
    "    #newDig(os.fsdecode(file))\n",
    "    #newDig(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"mnist_trained.h5\")\n",
    "\n",
    "def newDig(filepath):    \n",
    "    filepath = filepath\n",
    "    image_size = (28, 28)\n",
    "    im = image.load_img(filepath, target_size=image_size, color_mode=\"grayscale\")\n",
    "    from tensorflow.keras.preprocessing.image import img_to_array\n",
    "    image = img_to_array(im)\n",
    "    image.shape\n",
    "    # Scale the image pixels by 255 (or use a scaler from sklearn here)\n",
    "    image /= 255\n",
    "\n",
    "    # Flatten into a 1x28*28 array \n",
    "    img = image.flatten().reshape(-1, 28*28)\n",
    "    img.shape\n",
    "    plt.imshow(img.reshape(28, 28), cmap=plt.cm.Greys)\n",
    "    # Invert the pixel values to match the original data\n",
    "    img = 1 - img\n",
    "    plt.imshow(img.reshape(28, 28), cmap=plt.cm.Greys)\n",
    "    # Make predictions\n",
    "    return model.predict_classes(img)\n",
    "\n",
    "a = newDig(\"20321_1.png\")\n",
    "a\n",
    "\n",
    "b = newDig(\"20321_2.png\")\n",
    "b\n",
    "\n",
    "c = newDig(\"20321_3.png\")\n",
    "c\n",
    "\n",
    "d=newDig(\"20321_4.png\")\n",
    "d\n",
    "\n",
    "e =newDig(\"20321_5.png\")\n",
    "e\n",
    "\n",
    "full = str(a[0])+str(b[0])+str(c[0])+str(d[0])+str(e[0])\n",
    "full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##!!!!JUNK CODE FROM HERE!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "filepath = \"12345.png\"\n",
    "from tensorflow.keras.preprocessing import image\n",
    "image_size = (28, 28)\n",
    "im = image.load_img(filepath, target_size=image_size, color_mode=\"grayscale\")\n",
    "im\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "image = img_to_array(im)\n",
    "image.shape\n",
    "# Scale the image pixels by 255 (or use a scaler from sklearn here)\n",
    "image /= 255\n",
    "\n",
    "# Flatten into a 1x28*28 array \n",
    "img = image.flatten().reshape(-1, 28*28)\n",
    "img.shape\n",
    "plt.imshow(img.reshape(28, 28), cmap=plt.cm.Greys)\n",
    "# Invert the pixel values to match the original data\n",
    "img = 1 - img\n",
    "plt.imshow(img.reshape(28, 28), cmap=plt.cm.Greys)\n",
    "# Make predictions\n",
    "model.predict_classes(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "filepath = \"5041.png\"\n",
    "from tensorflow.keras.preprocessing import image\n",
    "image_size = (28, 28)\n",
    "im = image.load_img(filepath, target_size=image_size, color_mode=\"grayscale\")\n",
    "im\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "image = img_to_array(im)\n",
    "image.shape\n",
    "# Scale the image pixels by 255 (or use a scaler from sklearn here)\n",
    "image /= 255\n",
    "\n",
    "# Flatten into a 1x28*28 array \n",
    "img = image.flatten().reshape(-1, 28*28)\n",
    "img.shape\n",
    "plt.imshow(img.reshape(28, 28), cmap=plt.cm.Greys)\n",
    "# Invert the pixel values to match the original data\n",
    "img = 1 - img\n",
    "plt.imshow(img.reshape(28, 28), cmap=plt.cm.Greys)\n",
    "# Make predictions\n",
    "model.predict_classes(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = joblib.load('knn_model.pkl')\n",
    "def feature_extraction(image):\n",
    "    return hog(color.rgb2gray(image), orientations=8, pixels_per_cell=(10, 10), cells_per_block=(5, 5))\n",
    "def predict(df):\n",
    "    predict = knn.predict(df.reshape(1,-1))[0]\n",
    "    predict_proba = knn.predict_proba(df.reshape(1,-1))\n",
    "    return predict, predict_proba[0][predict]\n",
    "digits = []\n",
    "\n",
    "# load your image from file\n",
    "image = \"12345.png\"\n",
    "# extract featuress\n",
    "hogs = list(map(lambda x: feature_extraction(x), digits))\n",
    "# apply k-NN model created in previous\n",
    "predictions = list(map(lambda x: predict(x), hogs))\n",
    "\n",
    "hogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "training_digit_image = \"12345.png\"\n",
    "\n",
    "df= hog(training_digit_image, orientations=8, pixels_per_cell=(10,10), cells_per_block=(5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "filepath = \"12345.png\"\n",
    "from tensorflow.keras.preprocessing import image\n",
    "image_size = (28, 28)\n",
    "im = image.load_img(filepath, target_size=image_size, color_mode=\"grayscale\")\n",
    "im\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "image = img_to_array(im)\n",
    "image.shape\n",
    "# Scale the image pixels by 255 (or use a scaler from sklearn here)\n",
    "image /= 255\n",
    "\n",
    "# Flatten into a 1x28*28 array \n",
    "img = image.flatten().reshape(-1, 28*28)\n",
    "img.shape\n",
    "plt.imshow(img.reshape(28, 28), cmap=plt.cm.Greys)\n",
    "# Invert the pixel values to match the original data\n",
    "img = 1 - img\n",
    "plt.imshow(img.reshape(28, 28), cmap=plt.cm.Greys)\n",
    "# Make predictions\n",
    "model.predict_classes(img)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
